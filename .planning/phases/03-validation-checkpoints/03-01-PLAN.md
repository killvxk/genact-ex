---
phase: 03-validation-checkpoints
plan: 01
type: execute
wave: 1
depends_on: ["02-02"]
files_modified:
  - src/modules/llm_training.rs
autonomous: true

must_haves:
  truths:
    - "User sees validation phase start with visual separator after each epoch"
    - "User sees validation progress bar with loss, perplexity, accuracy metrics"
    - "User sees validation summary report comparing val_loss to train_loss"
    - "User sees checkpoint save messages with progress bar when val_loss improves"
    - "User sees checkpoint file path and size in safetensors format"
    - "User sees early stopping patience counter when val_loss does not improve"
    - "User sees occasional warning messages during validation (30-40% chance)"
  artifacts:
    - path: "src/modules/llm_training.rs"
      provides: "Validation and checkpoint phases"
      contains: "run_validation"
    - path: "src/modules/llm_training.rs"
      provides: "Checkpoint saving with progress"
      contains: "save_checkpoint"
  key_links:
    - from: "run_training_loop"
      to: "run_validation"
      via: "call after each epoch completes"
      pattern: "run_validation.*await"
    - from: "run_validation"
      to: "save_checkpoint"
      via: "conditional call when val_loss improves"
      pattern: "save_checkpoint.*await"
---

<objective>
Implement validation phase and checkpoint saving after each training epoch

Purpose: Users see validation progress with metrics, checkpoint saves when loss improves, and early stopping patience tracking. This completes the mid-training feedback loop that makes the simulation look like real LLM training with evaluation and model saving.

Output: Enhanced llm_training.rs with run_validation and save_checkpoint functions integrated into the training loop
</objective>

<execution_context>
@C:\Users\root\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\root\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-validation-checkpoints/03-CONTEXT.md
@.planning/phases/03-validation-checkpoints/03-RESEARCH.md
@src/modules/llm_training.rs
@src/modules/julia.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add save_checkpoint function with progress bar</name>
  <files>src/modules/llm_training.rs</files>
  <action>
Create `save_checkpoint` async function that simulates saving a checkpoint file with visual progress bar.

```rust
/// Save checkpoint with progress bar (simulated write)
async fn save_checkpoint(appconfig: &AppConfig, step: u32, file_size_gb: f32) {
    let mut rng = rng();
    let filename = format!("model-step-{}.safetensors", step);

    log_info(&format!(
        "Saving model checkpoint to ./checkpoints/{}",
        filename
    ))
    .await;

    let mut bar = BarBuilder::new()
        .total(100)
        .width(30)
        .full_char('=')
        .include_percent()
        .build();

    // Print initial progress line
    print(format!("  Writing {:.1}GB... {}", file_size_gb, bar)).await;
    newline().await;

    for i in 1..=100 {
        bar.replace(i);

        cursor_up(1).await;
        erase_line().await;
        print(format!("  Writing {:.1}GB... {}", file_size_gb, bar)).await;
        newline().await;

        if appconfig.should_exit() {
            return;
        }

        // Simulate write speed (~3-8 seconds total)
        csleep(rng.random_range(30..80)).await;
    }

    log_info(&format!(
        "Checkpoint saved: {} ({:.1}GB)",
        filename, file_size_gb
    ))
    .await;
}
```

Key features per CONTEXT.md:
- File naming: model-step-{N}.safetensors (modern HuggingFace format)
- GB-scale file sizes (2-8GB range)
- Progress bar for realistic write simulation
- Respects should_exit() for graceful termination
  </action>
  <verify>File compiles: `cargo check`</verify>
  <done>save_checkpoint function exists and compiles</done>
</task>

<task type="auto">
  <name>Task 2: Add warning message pool function</name>
  <files>src/modules/llm_training.rs</files>
  <action>
Create helper function to generate random validation warning messages (from RESEARCH.md patterns):

```rust
/// Get a random validation warning message
fn get_validation_warning(rng: &mut impl Rng, loss: f64) -> String {
    let warnings = [
        format!(
            "Gradient norm exceeds threshold (norm={:.2}), clipping applied",
            rng.random_range(5.0..15.0)
        ),
        "Detected potential numerical instability in attention scores".to_string(),
        format!(
            "Loss spike detected: current={:.4}, moving_avg={:.4}",
            loss * 1.1,
            loss
        ),
        "Memory pressure detected on GPU cluster, consider reducing batch size".to_string(),
        "Validation accuracy below training accuracy by >10%, possible overfitting".to_string(),
        format!("NaN detected in layer {}, batch skipped", rng.random_range(1..48)),
        "Gradient accumulation buffer near capacity".to_string(),
    ];

    warnings.choose(rng).unwrap().clone()
}
```

This pool provides variety in warning messages per CONTEXT.md requirement for realistic, serious-looking but non-alarming warnings.
  </action>
  <verify>File compiles: `cargo check`</verify>
  <done>get_validation_warning function exists and returns varied warnings</done>
</task>

<task type="auto">
  <name>Task 3: Implement run_validation function</name>
  <files>src/modules/llm_training.rs</files>
  <action>
Create `run_validation` async function following CONTEXT.md decisions and RESEARCH.md patterns.

```rust
/// Run validation phase after each epoch
async fn run_validation(
    appconfig: &AppConfig,
    epoch: u32,
    train_loss: f64,
    best_val_loss: &mut f64,
    total_steps: u32,
    patience: &mut u32,
    max_patience: u32,
) -> f64 {
    let mut rng = rng();

    // Validation configuration (per CONTEXT.md: 80-150 steps, 10-20 seconds)
    let val_steps = rng.random_range(80..150);

    // Visual separator (per CONTEXT.md: PyTorch Lightning style)
    newline().await;
    print(format!(
        "{}",
        Paint::cyan("=============== Validation ===============").bold()
    ))
    .await;
    newline().await;

    // Validation loss is 5-15% higher than training loss (CONTEXT.md)
    let val_loss_base = train_loss * (1.0 + rng.random_range(0.05..0.15));
    let noise_dist = Normal::new(0.0, 0.02).unwrap();

    // Validation progress bar (reuse training style)
    let mut bar = BarBuilder::new()
        .total(val_steps as usize)
        .width(35)
        .full_char('=')
        .include_percent()
        .build();

    let start_time = Instant::now();
    let mut current_val_loss = val_loss_base;

    // Print initial progress line
    print(format!("Val:   {} | Loss: -.----", bar)).await;
    newline().await;

    for step in 1..=val_steps {
        // Add noise to validation loss
        let noise: f64 = noise_dist.sample(&mut rng);
        current_val_loss = (val_loss_base * (1.0 + noise)).max(0.1);

        let ppl = current_val_loss.exp();
        let accuracy = (1.0 / (1.0 + current_val_loss)).min(0.95);
        let tokens_per_sec = rng.random_range(900_000.0..1_100_000.0);

        bar.replace(step as usize);

        // Update progress (single line update)
        cursor_up(1).await;
        erase_line().await;
        print(format!(
            "Val:   {} | Loss: {:.4} | PPL: {:.2} | Acc: {:.2}% | {:.0}tok/s",
            bar,
            current_val_loss,
            ppl,
            accuracy * 100.0,
            tokens_per_sec
        ))
        .await;
        newline().await;

        if appconfig.should_exit() {
            return current_val_loss;
        }

        // ~10-20 sec total: sleep_per_step = 10000-20000ms / 80-150 steps
        csleep(rng.random_range(80..150)).await;
    }

    let val_time = start_time.elapsed().as_secs_f64();
    let final_ppl = current_val_loss.exp();
    let final_accuracy = (1.0 / (1.0 + current_val_loss)).min(0.95);

    // Validation summary (multi-line report per CONTEXT.md)
    newline().await;
    log_info("Validation Results:").await;
    log_info(&format!("  val_loss:     {:.4}", current_val_loss)).await;
    log_info(&format!("  val_ppl:      {:.2}", final_ppl)).await;
    log_info(&format!("  val_accuracy: {:.2}%", final_accuracy * 100.0)).await;
    log_info(&format!(
        "  train_loss:   {:.4} (delta: {:+.4})",
        train_loss,
        current_val_loss - train_loss
    ))
    .await;
    log_info(&format!("  time:         {:.1}s", val_time)).await;

    // Random warning (30-40% chance per CONTEXT.md)
    if rng.random_bool(0.35) {
        log_warning(&get_validation_warning(&mut rng, current_val_loss)).await;
    }

    // Checkpoint logic (best model strategy per CONTEXT.md)
    if current_val_loss < *best_val_loss {
        *best_val_loss = current_val_loss;
        *patience = 0;

        // Save checkpoint with progress bar
        let file_size_gb: f32 = rng.random_range(2.0..8.0);
        save_checkpoint(appconfig, total_steps, file_size_gb).await;
    } else {
        *patience += 1;
        // Early stopping warning (never actually stops per CONTEXT.md)
        log_warning(&format!(
            "EarlyStopping: val_loss did not improve. Patience: {}/{}",
            patience, max_patience
        ))
        .await;
    }

    newline().await;

    current_val_loss
}
```

Key features:
- Visual separator in cyan (PyTorch Lightning style)
- Progress bar with extended metrics (loss, ppl, accuracy, tokens/sec)
- Multi-line validation summary report
- Checkpoint saving when loss improves
- Early stopping patience counter (never triggers)
- 30-40% warning probability
  </action>
  <verify>`cargo check` passes; function structure is complete</verify>
  <done>run_validation function implements all VAL and CKPT requirements</done>
</task>

<task type="auto">
  <name>Task 4: Integrate validation into training loop</name>
  <files>src/modules/llm_training.rs</files>
  <action>
Modify `run_training_loop` to call `run_validation` after each epoch:

1. Add state variables at the start of run_training_loop:
```rust
// Validation state
let mut best_val_loss = f64::MAX;
let mut patience: u32 = 0;
let max_patience: u32 = 5;
```

2. After the epoch summary log (after the inner step loop), add validation call:
```rust
// Run validation after each epoch
run_validation(
    appconfig,
    epoch,
    loss,
    &mut best_val_loss,
    total_steps,
    &mut patience,
    max_patience,
)
.await;

if appconfig.should_exit() {
    return;
}
```

3. Ensure the epoch summary and validation flow correctly:
- After epoch's steps complete
- Print epoch summary (existing)
- Call run_validation
- Re-print progress bars for next epoch (existing)

The integration point is after line ~297 (after the epoch summary log_info call).
  </action>
  <verify>`cargo check` passes; flow is correct</verify>
  <done>run_training_loop calls run_validation after each epoch</done>
</task>

<task type="auto">
  <name>Task 5: Verify and format</name>
  <files>src/modules/llm_training.rs</files>
  <action>
Run full verification:

1. `cargo fmt --all` - format code
2. `cargo clippy -- -D warnings` - lint check
3. `cargo run -- -m llm_training` - visual verification

Watch for:
- Validation separator appears after epoch ends
- Validation progress bar updates smoothly
- Metrics show loss, ppl, accuracy, tokens/sec
- Validation summary report shows comparison
- Checkpoint save appears with progress bar when loss improves
- Early stopping patience counter appears when loss doesn't improve
- Occasional warnings appear during validation
- Training continues normally after validation
  </action>
  <verify>
```bash
cargo fmt --all -- --check
cargo clippy -- -D warnings
cargo run -- -m llm_training
```
All pass; output shows complete training with validation phases and checkpoint saves.
  </verify>
  <done>
Complete validation and checkpoint simulation visible:
- Visual separator "=============== Validation ==============="
- Validation progress bar with metrics
- Summary report with val_loss, train_loss comparison
- Checkpoint saves with progress and file size
- Early stopping patience counter
- Occasional warnings
  </done>
</task>

</tasks>

<verification>
Run complete verification:
```bash
cargo fmt --all -- --check
cargo clippy -- -D warnings
cargo run -- -m llm_training
```

Expected output flow:
1. Initialization sequence (from Phase 2)
2. "======== Training Started ========"
3. Training epoch 1 with progress bars and GPU grid
4. Epoch 1 summary
5. "=============== Validation ==============="
6. Validation progress: `Val: [====...] 50% | Loss: 8.5432 | PPL: 5123.45 | Acc: 10.45% | 950000tok/s`
7. Validation summary report (val_loss, ppl, accuracy, train_loss delta, time)
8. Checkpoint save: "Saving model checkpoint to ./checkpoints/model-step-xxx.safetensors"
9. Checkpoint progress bar: "Writing 4.5GB... [====...] 75%"
10. "Checkpoint saved: model-step-xxx.safetensors (4.5GB)"
11. Training continues with epoch 2
12. Subsequent epochs show validation + possible early stopping patience
</verification>

<success_criteria>
- VAL-01: Validation phase start message visible with cyan separator
- VAL-02: Validation progress bar advancing with percentage
- VAL-03: Validation loss and perplexity metrics displayed
- CKPT-01: Checkpoint save messages appear periodically (when loss improves)
- CKPT-02: File path (./checkpoints/model-step-N.safetensors) and size (X.XGB) displayed
- Early stopping patience counter visible when loss doesn't improve
- Warning messages appear with ~35% probability
- Training continues smoothly after validation
- Passes cargo fmt and clippy checks
</success_criteria>

<output>
After completion, create `.planning/phases/03-validation-checkpoints/03-01-SUMMARY.md`
</output>
